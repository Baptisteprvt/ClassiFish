# import streamlit as st
# from PIL import Image
# from pathlib import Path
# from ultralytics import YOLO

# # Chemin du mod√®le YOLOv5
# MODEL_PATH = "Model/best.pt"

# # Esp√®ces d√©tectables par le mod√®le
# FISH_CLASSES = ["ABL", "ALA", "ANG", "BRE", "CHE", "HOT", "SIL"]

# # Dossier contenant les images √† classer
# IMAGE_FOLDER = Path("images_to_classify")  # √† adapter

# # Charger le mod√®le YOLO
# @st.cache_resource
# def load_model():
#     return YOLO(MODEL_PATH)

# model = load_model()

# # Liste des images √† classer
# @st.cache_data
# def get_image_list():
#     return sorted([p for p in IMAGE_FOLDER.glob("*.png")])

# # Interface principale
# def main():
#     st.title("üé£ Classification participative des poissons")

#     images = get_image_list()
#     if not images:
#         st.warning("Aucune image √† classer.")
#         return

#     # S√©lection d'une image (simple pour le moment, 1√®re de la liste)
#     index = st.session_state.get("image_index", 0)
#     if index >= len(images):
#         st.success("Toutes les images ont √©t√© class√©es !")
#         return

#     image_path = images[index]
#     img = Image.open(image_path)
#     st.image(img, caption=image_path.name, use_container_width=True)

#     # Pr√©diction IA
#     st.subheader("üîç Pr√©diction IA")
#     results = model.predict(source=image_path, imgsz=640, verbose=False)
#     pred_df = results[0]

#     # Obtenir l'ID de la classe pr√©dite
#     pred_class_id = int(pred_df.probs.top1)

#     # Mapper l'ID de la classe au nom de la classe
#     pred_class_name = model.names[pred_class_id]

#     st.write(f"Esp√®ce d√©tect√©e : {pred_class_name}")

#     # Annotation humaine
#     st.subheader("üßë‚Äçüî¨ Votre classification")
#     selected_class = st.radio("Quelle est l'esp√®ce de ce poisson ?", FISH_CLASSES)

#     if st.button("‚úÖ Soumettre"):
#         # TODO : Sauvegarder dans un fichier ou une DB locale
#         st.success(f"Annotation enregistr√©e : {selected_class}")
#         st.session_state.image_index = index + 1
#         st.rerun()

#     # Navigation manuelle
#     if st.button("‚è≠ Passer √† l'image suivante"):
#         st.session_state.image_index = index + 1
#         st.rerun()

# if __name__ == "__main__":
#     main()


# """

# """
import sys
import types

# Patch pour √©viter l'inspection de torch.classes
sys.modules["torch.classes"] = types.ModuleType("torch.classes")
import torch._classes
import os
import streamlit as st
import requests
import base64
from io import BytesIO
from PIL import Image
from ultralytics import YOLO
from dotenv import load_dotenv

# Chargement .env (pour backend_url si besoin)
load_dotenv()
BACKEND_URL = os.getenv("BACKEND_URL", "http://127.0.0.1:8000")

st.set_page_config(page_title="Classification Poissons", layout="centered")
st.title("üé£ Science participative : classifiez des poissons")

# Identifiant utilisateur
user_id = st.sidebar.text_input("Votre identifiant utilisateur")

# Charger mod√®le YOLO local
@st.cache_resource
def load_model():
    return YOLO("frontend/Model/best.pt")
model = load_model()

# Bouton nouvelle image
if st.button("Nouvelle image √† annoter"):
    res = requests.get(f"{BACKEND_URL}/image")
    if res.status_code == 200:
        data = res.json()
        st.session_state.img_id = data["image_id"]
        st.session_state.img_b64 = data["image"]
    else:
        st.error("Aucune image disponible.")

# Afficher si image charg√©e
if "img_b64" in st.session_state:
    img_bytes = base64.b64decode(st.session_state.img_b64)
    st.image(img_bytes, caption="Image √† annoter", use_container_width=True)
    img_pil = Image.open(BytesIO(img_bytes))

    # Pr√©diction IA locale
    st.subheader("üîç Pr√©diction IA (YOLO)")
    results = model(img_pil)
    if results and results[0].boxes.cls is not None:
        pred_ids = results[0].boxes.cls.cpu().numpy().astype(int)
        pred_names = [results[0].names[i] for i in pred_ids]
        pred_label = pred_names[0]
    else:
        pred_label = "Aucune d√©tect√©e"
    st.write(f"**Pr√©diction IA:** {pred_label}")

    # S√©lection humain
    st.subheader("üßë‚Äçüî¨ Votre classification")
    chosen = st.selectbox("Esp√®ce :", ["ABL","ALA","ANG","BRE","CHE","HOT","SIL"])

    # Soumettre annotation
    if st.button("‚úÖ Soumettre annotation"):
        if not user_id:
            st.warning("Entrez un identifiant utilisateur.")
        else:
            payload = {
                "image_id": st.session_state.img_id,
                "user_id": user_id,
                "label": chosen,
                "prediction_ia": pred_label
            }
            r = requests.post(f"{BACKEND_URL}/annotations", json=payload)
            if r.ok:
                st.success("Annotation enregistr√©e !")
            else:
                st.error(f"Erreur: {r.text}")

    # Vote IA
    agree = st.checkbox("La pr√©diction de l'IA est correcte")
    if agree and user_id:
        rv = requests.post(f"{BACKEND_URL}/vote", json={
            "image_id": st.session_state.img_id,
            "user_id": user_id,
            "vote": True
        })
        if rv.ok:
            st.info("Vote enregistr√©.")
        else:
            st.error("Erreur vote.")